{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c17d8f",
   "metadata": {},
   "source": [
    "# Data Analysis of the Health Care Provider Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c52201",
   "metadata": {},
   "source": [
    "In this notebook, we analyse the data and network structure of the Health Care Provider Dataset from kaggle. This mainly concerns the possibilities to split the data for training and testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3b02c",
   "metadata": {},
   "source": [
    "## Loading and inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61b2cd",
   "metadata": {},
   "source": [
    "The data provided on kaggle consists of four different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../data/HCP/Train.csv')\n",
    "beneficiary = pd.read_csv('../data/HCP/Train_Beneficiarydata.csv')\n",
    "inpatient = pd.read_csv('../data/HCP/Train_Inpatientdata.csv')\n",
    "outpatient = pd.read_csv('../data/HCP/Train_Outpatientdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab493f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Label'] = [0 if x=='No' else 1 for x in labels['PotentialFraud']]\n",
    "labels.set_index('Provider', inplace=True)\n",
    "labels = labels['Label']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094341dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bea5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpatient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d3bb3",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e87565",
   "metadata": {},
   "source": [
    "The labels are available for providers. These nodes do not have any features, so we will calculate the following features:\n",
    "* number of claims;\n",
    "* avg reembursed;\n",
    "* std reembursed;\n",
    "* number of claims per beneficiary.\n",
    "\n",
    "These summarise some key characteristics of the providers, that might help the algorithm uncover fraudulent behaviour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['Provider', 'BeneID', 'InscClaimAmtReimbursed']\n",
    "edges = pd.concat([inpatient[columns_to_select], outpatient[columns_to_select]])\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab29a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_claims = edges[['Provider', 'InscClaimAmtReimbursed']].groupby(['Provider']).count()\n",
    "number_of_claims.columns = ['number_of_claims']\n",
    "\n",
    "average_claims = edges[['Provider', 'InscClaimAmtReimbursed']].groupby(['Provider']).mean()\n",
    "average_claims.columns = ['average_claims']\n",
    "\n",
    "std_claims = edges[['Provider', 'InscClaimAmtReimbursed']].groupby(['Provider']).std()\n",
    "std_claims.columns = ['std_claims']\n",
    "\n",
    "number_of_beneficiaries = edges[['Provider', 'BeneID']].drop_duplicates().groupby(['Provider']).count()\n",
    "number_of_beneficiaries.columns = ['number_of_beneficiaries']\n",
    "\n",
    "provider_features = pd.concat([number_of_claims, average_claims, std_claims, number_of_beneficiaries], axis=1)\n",
    "provider_features.index.rename('Target', inplace=True)\n",
    "provider_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261988b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiary['Deceased'] = 1\n",
    "beneficiary.loc[beneficiary['DOD'].isna(), 'Deceased'] = 0\n",
    "beneficiary_features = beneficiary.drop(columns=[\"DOD\"])\n",
    "beneficiary_features.set_index('BeneID', inplace=True)\n",
    "beneficiary_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c626e8c",
   "metadata": {},
   "source": [
    "## Network construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965a5c0",
   "metadata": {},
   "source": [
    "For the network, we work exclusively with providers and beneficiaries. We will look at the connected components in an attempt to find a meaningful train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c68f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "for node in provider_features.index:\n",
    "    G.add_nodes_from([(node, {'label': 'provider'})])\n",
    "for node in beneficiary_features.index:\n",
    "    G.add_nodes_from([(node, {'label': 'beneficiary'})])\n",
    "\n",
    "G.add_edges_from(edges[['Provider', 'BeneID']].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in nx.connected_components(G):\n",
    "    print(f\"Component of size {len(component)}:\")\n",
    "\n",
    "list_components = list(nx.connected_components(G))\n",
    "largest_component = max(list_components, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G.subgraph(largest_component).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70998c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw network with colourmap according to label of node\n",
    "ego_net = nx.ego_graph(G, 'PRV51001', radius=3)\n",
    "node_colors = ['blue' if ego_net.nodes[n]['label'] == 'provider' else 'orange' for n in ego_net.nodes()]\n",
    "nx.draw_networkx(ego_net, with_labels=False, node_size=50, font_size=5, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f4ca9",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85be8d",
   "metadata": {},
   "source": [
    "The train-test split can be done in many different ways. Here, we opt to apply the louvain community detection method. The resulting communities are used to split the graph into two groups, one for training and one for testing. \n",
    "\n",
    "We set the resolution parameter quite low to favour large communities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = nx.community.louvain_communities(G, resolution=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a33e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for com in communities:\n",
    "    print(f\"Community of size: {len(com)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_1 = communities[1:4]\n",
    "com_1_nodes = [node for com in com_1 for node in com]\n",
    "com_2 = [communities[i] for i in [0,4,5]]\n",
    "com_2_nodes = [node for com in com_2 for node in com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df992c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = G.subgraph(com_1_nodes)\n",
    "G_test = G.subgraph(com_2_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_beneficiaries_train = beneficiary_features.loc[[n for n, d in G_train.nodes(data=True) if d['label'] == 'beneficiary']]\n",
    "dataset_providers_train = provider_features.loc[[n for n, d in G_train.nodes(data=True) if d['label'] == 'provider']]\n",
    "\n",
    "dataset_beneficiaries_test = beneficiary_features.loc[[n for n, d in G_test.nodes(data=True) if d['label'] == 'beneficiary']]\n",
    "dataset_providers_test = provider_features.loc[[n for n, d in G_test.nodes(data=True) if d['label'] == 'provider']]\n",
    "\n",
    "labels_providers_train = labels.loc[dataset_providers_train.index]\n",
    "labels_providers_test = labels.loc[dataset_providers_test.index]\n",
    "\n",
    "# Beneficiaries don't have labels. Make dataframes with all 0's\n",
    "labels_beneficiaries_train = pd.DataFrame(0, index=dataset_beneficiaries_train.index, columns=['Label'])\n",
    "labels_beneficiaries_test = pd.DataFrame(0, index=dataset_beneficiaries_test.index, columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [\n",
    "    G_train, \n",
    "    dataset_providers_train, \n",
    "    dataset_beneficiaries_train, \n",
    "    labels_providers_train,\n",
    "    labels_beneficiaries_train\n",
    "]\n",
    "\n",
    "x_test = [\n",
    "    G_test, \n",
    "    dataset_providers_test, \n",
    "    dataset_beneficiaries_test, \n",
    "    labels_providers_test,\n",
    "    labels_beneficiaries_test\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec43cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/HCP/hcp_train.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train, f)\n",
    "\n",
    "with open('../data/HCP/hcp_test.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8665c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225422fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBDT38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
